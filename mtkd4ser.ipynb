{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalto-speech/mtkd4ser/blob/EN_FI_FR/mtkd4ser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the github repository"
      ],
      "metadata": {
        "id": "cqQfTvW-Rh5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2CbN12tVzSYN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/aalto-speech/mtkd4ser.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the required packages"
      ],
      "metadata": {
        "id": "_eM3XnLJRpyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mN9IhXpL1hI6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "nZYseSuUSTmA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U transformers[torch] datasets"
      ],
      "metadata": {
        "id": "tq3AV_CmSSjz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorboards"
      ],
      "metadata": {
        "id": "6SBr7-MySWSk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "StxNQRHyRwny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lris1DP21SDk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch datasets"
      ],
      "metadata": {
        "id": "wjRxgqbNR5I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# print(\"Upload the kaggle.json file\")\n",
        "# files.upload()\n",
        "# time.sleep(5)\n",
        "\n",
        "# os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "# !mv kaggle.json /root/.kaggle/\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# time.sleep(5)\n",
        "\n",
        "# !kaggle datasets download -d dejolilandry/iemocapfullrelease\n",
        "# time.sleep(5)\n",
        "\n",
        "# with zipfile.ZipFile('iemocapfullrelease.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/')\n",
        "# time.sleep(5)\n",
        "\n",
        "# !gdown --id 16eCv6Sa4hklMoEk3ahp4lc1V561Elrml\n",
        "# time.sleep(5)\n",
        "\n",
        "# !unzip /content/IEMOCAP_splits.zip\n",
        "# time.sleep(5)"
      ],
      "metadata": {
        "id": "oaOE15B0SHGc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "an50oRbFzTJ3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!gdown --id 1EZTvcHo2x3cim4uSTkfMHoagipfQtLak\n",
        "time.sleep(5)\n",
        "\n",
        "!unzip /content/FESC_CaFE.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute the main.py script from the cloned repository with speficied hyperparameters"
      ],
      "metadata": {
        "id": "o3ZIGEjeSa_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2DeXolLzTVe",
        "outputId": "ce9d004a-0b56-4649-b0af-abbce02aec6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-08-30 12:41:33.347968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-30 12:41:33.367440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-30 12:41:33.373839: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-30 12:41:33.388823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-30 12:41:34.494784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'label'],\n",
            "        num_rows: 420\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'label'],\n",
            "        num_rows: 84\n",
            "    })\n",
            "    dev: Dataset({\n",
            "        features: ['audio', 'label'],\n",
            "        num_rows: 84\n",
            "    })\n",
            "})\n",
            "{'anger': '0', 'happiness': '1', 'neutral': '2', 'sadness': '3'}\n",
            "{'0': 'anger', '1': 'happiness', '2': 'neutral', '3': 'sadness'}\n",
            "preprocessor_config.json: 100% 159/159 [00:00<00:00, 1.28MB/s]\n",
            "Map: 100% 420/420 [00:14<00:00, 28.00 examples/s]\n",
            "Map: 100% 84/84 [00:00<00:00, 177.91 examples/s]\n",
            "Map: 100% 84/84 [00:00<00:00, 178.83 examples/s]\n",
            "config.json: 100% 1.84k/1.84k [00:00<00:00, 12.5MB/s]\n",
            "pytorch_model.bin: 100% 380M/380M [00:01<00:00, 260MB/s]\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1/5, Training Recall (unweighted): 0.3729166666666667, Recall (weighted): 0.4261904761904762, Accuracy: 0.4261904761904762, Loss: 1.2631620742656566\n",
            "Epoch 1/5, Validation Recall (unweighted): 0.39583333333333337, Validation Recall (weighted): 0.4523809523809524, Validation Accuracy: 0.4523809523809524, Validation Loss: 1.1771469314893086\n",
            "\n",
            "Model has been saved after epoch: 1\n",
            "\n",
            "Epoch 2/5, Training Recall (unweighted): 0.475, Recall (weighted): 0.5428571428571428, Accuracy: 0.5428571428571428, Loss: 1.0543341636657715\n",
            "Epoch 2/5, Validation Recall (unweighted): 0.53125, Validation Recall (weighted): 0.6071428571428571, Validation Accuracy: 0.6071428571428571, Validation Loss: 1.027514119942983\n",
            "\n",
            "Model has been saved after epoch: 2\n",
            "\n",
            "Epoch 3/5, Training Recall (unweighted): 0.5791666666666667, Recall (weighted): 0.6571428571428571, Accuracy: 0.6571428571428571, Loss: 0.8598432585045144\n",
            "Epoch 3/5, Validation Recall (unweighted): 0.46875, Validation Recall (weighted): 0.5238095238095238, Validation Accuracy: 0.5238095238095238, Validation Loss: 0.9857479333877563\n",
            "\n",
            "Model has been saved after epoch: 3\n",
            "\n",
            "Epoch 4/5, Training Recall (unweighted): 0.7645833333333334, Recall (weighted): 0.8261904761904761, Accuracy: 0.8261904761904761, Loss: 0.6079356571038564\n",
            "Epoch 4/5, Validation Recall (unweighted): 0.6458333333333334, Validation Recall (weighted): 0.6785714285714286, Validation Accuracy: 0.6785714285714286, Validation Loss: 0.8940893610318502\n",
            "\n",
            "Model has been saved after epoch: 4\n",
            "\n",
            "Epoch 5/5, Training Recall (unweighted): 0.89375, Recall (weighted): 0.9119047619047619, Accuracy: 0.9119047619047619, Loss: 0.40064354792789175\n",
            "Epoch 5/5, Validation Recall (unweighted): 0.625, Validation Recall (weighted): 0.6309523809523809, Validation Accuracy: 0.6309523809523809, Validation Loss: 0.884041373928388\n",
            "\n",
            "Model has been saved after epoch: 5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the model for French Speech Emotion Recognition (SER) using the monolingual setting\n",
        "!python /content/mtkd4ser/main.py --LEARNING_RATE 3e-5 --BATCH_SIZE 16 --N_EPOCHS 5 --SESSION 1 --TRAINING 1 --PARADIGM \"FT\" --LANGUAGE \"FR\" --LINGUALITY \"Monolingual\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBQVMMISAnDm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xYEp65NAnGN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ro44diTtAnI8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obgSjAivAnLa"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNILnNRvn1YCXTQ1E20K8iL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}